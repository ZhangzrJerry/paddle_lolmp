{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T06:21:47.794520Z",
     "iopub.status.busy": "2022-08-11T06:21:47.793697Z",
     "iopub.status.idle": "2022-08-11T06:21:48.279577Z",
     "shell.execute_reply": "2022-08-11T06:21:48.278845Z",
     "shell.execute_reply.started": "2022-08-11T06:21:47.794490Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['win', 'kills', 'deaths', 'assists', 'largestkillingspree',\n",
      "       'largestmultikill', 'longesttimespentliving', 'doublekills',\n",
      "       'triplekills', 'quadrakills', 'pentakills', 'totdmgdealt',\n",
      "       'magicdmgdealt', 'physicaldmgdealt', 'truedmgdealt', 'largestcrit',\n",
      "       'totdmgtochamp', 'magicdmgtochamp', 'physdmgtochamp', 'truedmgtochamp',\n",
      "       'totheal', 'totunitshealed', 'dmgtoturrets', 'timecc', 'totdmgtaken',\n",
      "       'magicdmgtaken', 'physdmgtaken', 'truedmgtaken', 'wardsplaced',\n",
      "       'wardskilled', 'firstblood'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import paddle\n",
    "# 导入训练数据\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_train = df_train.drop(['id'],axis=1)\n",
    "# 对特征进行归一化\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(df_train.iloc[:,0:])  \n",
    "scaler_data = scaler.transform(df_train.iloc[:,0:])\n",
    "# 将训练数据集和测试数据集按照8:2的比例分开\n",
    "ratio = 0.8\n",
    "offset = int(df_train.shape[0] * ratio)\n",
    "train_data = np.c_[scaler_data,df_train.iloc[:,0]][:offset].copy()\n",
    "test_data = np.c_[scaler_data,df_train.iloc[:,0]][offset:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP模型组网搭建\n",
    "n_input = 30\n",
    "from paddle import nn\n",
    "class Classifier(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.l1 = paddle.nn.Linear(n_input, 1,)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        pred = self.l1(inputs)\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training ... \n",
      "Pass:0,Cost:1.64892\n",
      "Pass:0,Cost:1.70996\n",
      "Pass:0,Cost:0.82808\n",
      "Pass:0,Cost:1.06871\n",
      "Pass:0,Cost:1.26932\n",
      "Pass:0,Cost:0.36407\n",
      "Pass:0,Cost:0.48923\n",
      "Pass:0,Cost:0.69038\n",
      "Pass:0,Cost:1.16748\n",
      "Pass:0,Cost:0.48667\n",
      "Pass:0,Cost:0.32061\n",
      "Pass:0,Cost:0.50801\n",
      "Pass:0,Cost:0.49127\n",
      "Pass:0,Cost:0.77959\n",
      "Pass:0,Cost:0.24992\n",
      "Pass:0,Cost:0.41158\n",
      "Pass:0,Cost:0.57962\n",
      "Pass:0,Cost:0.21543\n",
      "Pass:0,Cost:0.26191\n",
      "Pass:0,Cost:0.11424\n",
      "Pass:0,Cost:0.15846\n",
      "Pass:0,Cost:0.17296\n",
      "Pass:0,Cost:0.21713\n",
      "Pass:0,Cost:0.33425\n",
      "Pass:0,Cost:0.13636\n",
      "Pass:0,Cost:0.10134\n",
      "Pass:0,Cost:0.12961\n",
      "Pass:0,Cost:0.09740\n",
      "Pass:0,Cost:0.12857\n",
      "Pass:0,Cost:0.15691\n",
      "Pass:0,Cost:0.09825\n",
      "Pass:0,Cost:0.08822\n",
      "Pass:0,Cost:0.07738\n",
      "Pass:0,Cost:0.12253\n",
      "Pass:0,Cost:0.07916\n",
      "Pass:0,Cost:0.16457\n",
      "Pass:0,Cost:0.03725\n",
      "Pass:0,Cost:0.05173\n",
      "Pass:0,Cost:0.09931\n",
      "Pass:0,Cost:0.09538\n",
      "Pass:0,Cost:0.10207\n",
      "Pass:0,Cost:0.03770\n",
      "Pass:0,Cost:0.06988\n",
      "Pass:0,Cost:0.05353\n",
      "Pass:0,Cost:0.09008\n",
      "Pass:0,Cost:0.04047\n",
      "Pass:0,Cost:0.07170\n",
      "Pass:0,Cost:0.03304\n",
      "Pass:0,Cost:0.04270\n",
      "Pass:0,Cost:0.06216\n",
      "Pass:0,Cost:0.03693\n",
      "Pass:0,Cost:0.03579\n",
      "Pass:0,Cost:0.04741\n",
      "Pass:0,Cost:0.04230\n",
      "Pass:0,Cost:0.04763\n",
      "Pass:0,Cost:0.03317\n",
      "Pass:0,Cost:0.04355\n",
      "Pass:0,Cost:0.03737\n",
      "Pass:0,Cost:0.04402\n",
      "Pass:0,Cost:0.02400\n",
      "Pass:0,Cost:0.05016\n",
      "Pass:0,Cost:0.05220\n",
      "Pass:0,Cost:0.02101\n",
      "Pass:0,Cost:0.02671\n",
      "Pass:0,Cost:0.01346\n",
      "Pass:0,Cost:0.01731\n",
      "Pass:0,Cost:0.05729\n",
      "Pass:0,Cost:0.02479\n",
      "Pass:0,Cost:0.02297\n",
      "Pass:0,Cost:0.01450\n",
      "Pass:0,Cost:0.06270\n",
      "Pass:0,Cost:0.01922\n",
      "Pass:0,Cost:0.01066\n",
      "Pass:0,Cost:0.03359\n",
      "Pass:0,Cost:0.02252\n",
      "Pass:0,Cost:0.01365\n",
      "Pass:0,Cost:0.02539\n",
      "Pass:0,Cost:0.02664\n",
      "Pass:0,Cost:0.01398\n",
      "Pass:0,Cost:0.04021\n",
      "Pass:0,Cost:0.01822\n",
      "Pass:0,Cost:0.04265\n",
      "Pass:0,Cost:0.01434\n",
      "Pass:0,Cost:0.05519\n",
      "Pass:0,Cost:0.01932\n",
      "Pass:0,Cost:0.01681\n",
      "Pass:0,Cost:0.01093\n",
      "Pass:0,Cost:0.04500\n",
      "Pass:0,Cost:0.02896\n",
      "Pass:0,Cost:0.00759\n",
      "Pass:0,Cost:0.02947\n",
      "Pass:0,Cost:0.01503\n",
      "Pass:0,Cost:0.02450\n",
      "Pass:0,Cost:0.00960\n",
      "Pass:0,Cost:0.01403\n",
      "Pass:0,Cost:0.02293\n",
      "Pass:0,Cost:0.03146\n",
      "Pass:0,Cost:0.01089\n",
      "Pass:0,Cost:0.01090\n",
      "Pass:0,Cost:0.00880\n",
      "Pass:0,Cost:0.01880\n",
      "Pass:0,Cost:0.01930\n",
      "Pass:0,Cost:0.01264\n",
      "Pass:0,Cost:0.01601\n",
      "Pass:0,Cost:0.00988\n",
      "Pass:0,Cost:0.00596\n",
      "Pass:0,Cost:0.00778\n",
      "Pass:0,Cost:0.00789\n",
      "Pass:0,Cost:0.00933\n",
      "Pass:0,Cost:0.00952\n",
      "Pass:0,Cost:0.02145\n",
      "Pass:0,Cost:0.00975\n",
      "Pass:0,Cost:0.01483\n",
      "Pass:0,Cost:0.01712\n",
      "Pass:0,Cost:0.00416\n",
      "Pass:0,Cost:0.00867\n",
      "Pass:0,Cost:0.00682\n",
      "Pass:0,Cost:0.01005\n",
      "Pass:0,Cost:0.01284\n",
      "Pass:0,Cost:0.00710\n",
      "Pass:0,Cost:0.00822\n",
      "Pass:0,Cost:0.00773\n",
      "Pass:0,Cost:0.01744\n",
      "Pass:0,Cost:0.00448\n",
      "Pass:0,Cost:0.01685\n",
      "Pass:0,Cost:0.01186\n",
      "Pass:0,Cost:0.00680\n",
      "Pass:0,Cost:0.00731\n",
      "Pass:0,Cost:0.00388\n",
      "Pass:0,Cost:0.00875\n",
      "Pass:0,Cost:0.00273\n",
      "Pass:0,Cost:0.01030\n",
      "Pass:0,Cost:0.00984\n",
      "Pass:0,Cost:0.01087\n",
      "Pass:0,Cost:0.00685\n",
      "Pass:0,Cost:0.00433\n",
      "Pass:0,Cost:0.00579\n",
      "Pass:0,Cost:0.00791\n",
      "Pass:0,Cost:0.00399\n",
      "Pass:0,Cost:0.00836\n",
      "Pass:0,Cost:0.01198\n",
      "Pass:0,Cost:0.00772\n",
      "Pass:0,Cost:0.01163\n",
      "Pass:0,Cost:0.00555\n",
      "Pass:0,Cost:0.00504\n",
      "Pass:0,Cost:0.00504\n",
      "Pass:0,Cost:0.01021\n",
      "Pass:0,Cost:0.01428\n",
      "Pass:0,Cost:0.00371\n",
      "Pass:0,Cost:0.00263\n",
      "Pass:0,Cost:0.00433\n",
      "Pass:0,Cost:0.00367\n",
      "Pass:0,Cost:0.00509\n",
      "Pass:0,Cost:0.00213\n",
      "Pass:0,Cost:0.00436\n",
      "Pass:0,Cost:0.00483\n",
      "Pass:0,Cost:0.00335\n",
      "Pass:0,Cost:0.00190\n",
      "Pass:0,Cost:0.00245\n",
      "Pass:0,Cost:0.00381\n",
      "Pass:0,Cost:0.00501\n",
      "Pass:0,Cost:0.00433\n",
      "Pass:0,Cost:0.00257\n",
      "Pass:0,Cost:0.00469\n",
      "Pass:0,Cost:0.00292\n",
      "Pass:0,Cost:0.00302\n",
      "Pass:0,Cost:0.00269\n",
      "Pass:0,Cost:0.00219\n",
      "Pass:0,Cost:0.00280\n",
      "Pass:0,Cost:0.00514\n",
      "Pass:0,Cost:0.00343\n",
      "Pass:0,Cost:0.00398\n",
      "Pass:0,Cost:0.00255\n",
      "Pass:0,Cost:0.00568\n",
      "Pass:0,Cost:0.00189\n",
      "Pass:0,Cost:0.00464\n",
      "Pass:0,Cost:0.00573\n",
      "Pass:0,Cost:0.00469\n",
      "Pass:0,Cost:0.00477\n",
      "Pass:0,Cost:0.00203\n",
      "Pass:0,Cost:0.00415\n",
      "Pass:0,Cost:0.00494\n",
      "Pass:0,Cost:0.00435\n",
      "Pass:0,Cost:0.00490\n",
      "Pass:0,Cost:0.00438\n",
      "Pass:0,Cost:0.00570\n",
      "Pass:0,Cost:0.00269\n",
      "Pass:0,Cost:0.00158\n",
      "Pass:0,Cost:0.00398\n",
      "Pass:0,Cost:0.00390\n",
      "Pass:0,Cost:0.00401\n",
      "Pass:0,Cost:0.00186\n",
      "Pass:0,Cost:0.00389\n",
      "Pass:0,Cost:0.00261\n",
      "Pass:0,Cost:0.00389\n",
      "Pass:0,Cost:0.00094\n",
      "Pass:0,Cost:0.00252\n",
      "Pass:0,Cost:0.00186\n",
      "Pass:0,Cost:0.00297\n",
      "Pass:0,Cost:0.00223\n",
      "Pass:0,Cost:0.00233\n",
      "Pass:0,Cost:0.00142\n",
      "Pass:0,Cost:0.00182\n",
      "Pass:0,Cost:0.00360\n",
      "Pass:0,Cost:0.00159\n",
      "Pass:0,Cost:0.00171\n",
      "Pass:0,Cost:0.00115\n",
      "Pass:0,Cost:0.00582\n",
      "Pass:0,Cost:0.00173\n",
      "Pass:0,Cost:0.00224\n",
      "Pass:0,Cost:0.00380\n",
      "Pass:0,Cost:0.00122\n",
      "Pass:0,Cost:0.00252\n",
      "Pass:0,Cost:0.00344\n",
      "Pass:0,Cost:0.00343\n",
      "Pass:0,Cost:0.00213\n",
      "Pass:0,Cost:0.00281\n",
      "Pass:0,Cost:0.00162\n",
      "Pass:0,Cost:0.00323\n",
      "Pass:0,Cost:0.00136\n",
      "Pass:0,Cost:0.00240\n",
      "Pass:0,Cost:0.00168\n",
      "Pass:0,Cost:0.00180\n",
      "Pass:0,Cost:0.00231\n",
      "Pass:0,Cost:0.00123\n",
      "Pass:0,Cost:0.00262\n",
      "Pass:0,Cost:0.00167\n",
      "Pass:0,Cost:0.00293\n",
      "Pass:0,Cost:0.00270\n",
      "Pass:0,Cost:0.00124\n",
      "Pass:0,Cost:0.00087\n",
      "Pass:0,Cost:0.00130\n",
      "Pass:0,Cost:0.00094\n",
      "Pass:0,Cost:0.00099\n",
      "Pass:0,Cost:0.00260\n",
      "Pass:0,Cost:0.00132\n",
      "Pass:0,Cost:0.00119\n",
      "Pass:0,Cost:0.00231\n",
      "Pass:0,Cost:0.00260\n",
      "Pass:0,Cost:0.00219\n"
     ]
    }
   ],
   "source": [
    "import paddle.nn.functional as F \n",
    "y_preds = []\n",
    "train_nums = []\n",
    "train_costs = []\n",
    "labels_list = []\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "def train(model):\n",
    "    print('start training ... ')\n",
    "    # 开启模型训练模式\n",
    "    model.train()\n",
    "    EPOCH_NUM = 5\n",
    "    train_num = 0\n",
    "    optimizer = paddle.optimizer.SGD(learning_rate=0.001, parameters=model.parameters())\n",
    "    for epoch_id in range(EPOCH_NUM):\n",
    "        # 在每轮迭代开始之前，将训练数据的顺序随机的打乱\n",
    "        np.random.shuffle(train_data)\n",
    "        # 将训练数据进行拆分，每个batch包含20条数据\n",
    "        mini_batches = [train_data[k: k+BATCH_SIZE] for k in range(0, len(train_data), BATCH_SIZE)]\n",
    "        for batch_id, data in enumerate(mini_batches):\n",
    "            features_np = np.array(data[:, :n_input], np.float32)\n",
    "            labels_np = np.array(data[:, -1:], np.float32)\n",
    "            features = paddle.to_tensor(features_np)\n",
    "            labels = paddle.to_tensor(labels_np)\n",
    "            # 前向计算\n",
    "            y_pred = model(features)\n",
    "            cost = F.mse_loss(y_pred, label=labels)\n",
    "            train_cost = cost.numpy()[0]\n",
    "            # 反向传播\n",
    "            cost.backward()\n",
    "            # 最小化loss，更新参数\n",
    "            optimizer.step()\n",
    "            # 清除梯度\n",
    "            optimizer.clear_grad()\n",
    "            \n",
    "            if batch_id%30 == 0 and epoch_id%50 == 0:\n",
    "                print(\"Pass:%d,Cost:%0.5f\"%(epoch_id, train_cost))\n",
    "\n",
    "            train_num = train_num + BATCH_SIZE\n",
    "            train_nums.append(train_num)\n",
    "            train_costs.append(train_cost)\n",
    "        \n",
    "model = Classifier()\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def draw_train_process(iters, train_costs):\n",
    "    plt.title(\"training cost\", fontsize=24)\n",
    "    plt.xlabel(\"iter\", fontsize=14)\n",
    "    plt.ylabel(\"cost\", fontsize=14)\n",
    "    plt.plot(iters, train_costs, color='red', label='training cost')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "%matplotlib inline\n",
    "draw_train_process(train_nums, train_costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T06:15:13.102588Z",
     "iopub.status.busy": "2022-08-11T06:15:13.101823Z",
     "iopub.status.idle": "2022-08-11T06:15:14.090211Z",
     "shell.execute_reply": "2022-08-11T06:15:14.089233Z",
     "shell.execute_reply.started": "2022-08-11T06:15:13.102560Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.0423225 , -0.24851945, -1.0652921 , -1.0532238 , -0.43834025,\n",
       "         -0.19826205, -0.58423096, -0.24698801, -0.09784286, -0.04000573,\n",
       "         -1.188272  , -0.7809258 , -0.6200115 , -0.28191438, -0.5774179 ,\n",
       "         -1.2297674 , -0.8086368 , -0.564268  , -0.61155623, -0.82438904,\n",
       "         -0.10260557, -0.7286519 ,  0.        , -1.2983824 , -1.155188  ,\n",
       "         -1.1353154 , -0.51228553, -0.9952254 , -0.35158026, -0.33337447]],\n",
       "       dtype=float32),\n",
       " array([0], dtype=int64))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from paddle.io import Dataset\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    步骤一：继承 paddle.io.Dataset 类\n",
    "    \"\"\"\n",
    "    def __init__(self, x, y):\n",
    "        \"\"\"\n",
    "        步骤二：实现 __init__ 函数，初始化数据集，将样本和标签映射到列表中\n",
    "        \"\"\"\n",
    "        super(MyDataset, self).__init__()\n",
    "        self.data_list = []\n",
    "        for i,j in zip(x,y):\n",
    "            self.data_list.append([i,j])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        步骤三：实现 __getitem__ 函数，定义指定 index 时如何获取数据，并返回单条数据（样本数据、对应的标签）\n",
    "        \"\"\"\n",
    "        data = self.data_list[index]\n",
    "        feature = np.array(data[:-1]).astype('float32')\n",
    "        label = np.array(data[-1:]).astype('int64')\n",
    "        # 返回特征和对应标签\n",
    "        return feature, label\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        步骤四：实现 __len__ 函数，返回数据集的样本总数\n",
    "        \"\"\"\n",
    "        return len(self.data_list)\n",
    "\n",
    "train_dataset = MyDataset(x_train,y_train)\n",
    "test_dataset = MyDataset(x_test,y_test)\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 来自https://www.baidu.com/link?url=hSEYSblNYfUpxy02rFPNyzfM9tGUUYgq2l09k759J-Fi-MjmmTuYPr9t52EHkXDjpZUiRMvEDoAtNpwfLCPFIKXW9G-QxvS6nc2RaXygDha&wd=&eqid=f4215a8e000bfe7e0000000662f6893c\n",
    "class MyNet(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(MyNet,self).__init__()\n",
    "        self.fc = paddle.nn.Linear(in_features=21, out_features=512)\n",
    "\n",
    "        self.emb1 = paddle.nn.Linear(in_features=10,out_features=2048)\n",
    "        self.emb2 = paddle.nn.Linear(in_features=2048,out_features=512)\n",
    "\n",
    "        self.out = paddle.nn.Linear(in_features=1024,out_features=2)\n",
    "\n",
    "    def forward(self,data,emb_data):\n",
    "        x = self.fc(data)\n",
    "\n",
    "        emb = self.emb1(emb_data)\n",
    "        emb = self.emb2(emb)\n",
    "\n",
    "        x = paddle.concat([x,emb],axis=-1)\n",
    "\n",
    "        x = self.out(x)\n",
    "        \n",
    "        x = paddle.nn.functional.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = paddle.io.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=1000,\n",
    "    shuffle=True,\n",
    "    drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\项目\\让我们荡起飞桨\\飞桨_英雄联盟\\main.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%E9%A1%B9%E7%9B%AE/%E8%AE%A9%E6%88%91%E4%BB%AC%E8%8D%A1%E8%B5%B7%E9%A3%9E%E6%A1%A8/%E9%A3%9E%E6%A1%A8_%E8%8B%B1%E9%9B%84%E8%81%94%E7%9B%9F/main.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m step, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_dataloader):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E9%A1%B9%E7%9B%AE/%E8%AE%A9%E6%88%91%E4%BB%AC%E8%8D%A1%E8%B5%B7%E9%A3%9E%E6%A1%A8/%E9%A3%9E%E6%A1%A8_%E8%8B%B1%E9%9B%84%E8%81%94%E7%9B%9F/main.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     now_step\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/%E9%A1%B9%E7%9B%AE/%E8%AE%A9%E6%88%91%E4%BB%AC%E8%8D%A1%E8%B5%B7%E9%A3%9E%E6%A1%A8/%E9%A3%9E%E6%A1%A8_%E8%8B%B1%E9%9B%84%E8%81%94%E7%9B%9F/main.ipynb#X13sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     data,emb_data, label \u001b[39m=\u001b[39m data\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E9%A1%B9%E7%9B%AE/%E8%AE%A9%E6%88%91%E4%BB%AC%E8%8D%A1%E8%B5%B7%E9%A3%9E%E6%A1%A8/%E9%A3%9E%E6%A1%A8_%E8%8B%B1%E9%9B%84%E8%81%94%E7%9B%9F/main.ipynb#X13sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     pre \u001b[39m=\u001b[39m model(data,emb_data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E9%A1%B9%E7%9B%AE/%E8%AE%A9%E6%88%91%E4%BB%AC%E8%8D%A1%E8%B5%B7%E9%A3%9E%E6%A1%A8/%E9%A3%9E%E6%A1%A8_%E8%8B%B1%E9%9B%84%E8%81%94%E7%9B%9F/main.ipynb#X13sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     loss \u001b[39m=\u001b[39m paddle\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mcross_entropy(pre,label,weight\u001b[39m=\u001b[39mpaddle\u001b[39m.\u001b[39mto_tensor([\u001b[39m0.2\u001b[39m,\u001b[39m1.0\u001b[39m]),reduction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "model = MyNet()\n",
    "\n",
    "max_epoch=10\n",
    "opt = paddle.optimizer.SGD(learning_rate=0.1, parameters=model.parameters())\n",
    "\n",
    "# 训练\n",
    "now_step=0\n",
    "for epoch in range(max_epoch):\n",
    "    for step, data in enumerate(train_dataloader):\n",
    "        now_step+=1\n",
    "\n",
    "        data,emb_data, label = data\n",
    "        pre = model(data,emb_data)\n",
    "        loss = paddle.nn.functional.cross_entropy(pre,label,weight=paddle.to_tensor([0.2,1.0]),reduction='mean')\n",
    "        # loss = paddle.nn.functional.square_error_cost(pre,label.reshape([-1,1]).astype('float32'))\n",
    "        # loss = paddle.mean(loss)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.clear_gradients()\n",
    "        if now_step%1==0:\n",
    "            print(\"epoch: {}, batch: {}, loss is: {}\".format(epoch, step, loss.mean().numpy()))\n",
    "\n",
    "# 保存模型到model.pdparams\n",
    "paddle.save(model.state_dict(), 'model.pdparams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "(InvalidArgument) The type of data we are trying to retrieve does not match the type of data currently contained in the container.\n  [Hint: Expected dtype() == paddle::experimental::CppTypeToDataType<T>::Type(), but received dtype():7 != paddle::experimental::CppTypeToDataType<T>::Type():12.] (at C:\\home\\workspace\\Paddle_release\\paddle\\phi\\core\\dense_tensor.cc:137)\n  [operator < elementwise_sub > error]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\项目\\让我们荡起飞桨\\飞桨_英雄联盟\\main.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E9%A1%B9%E7%9B%AE/%E8%AE%A9%E6%88%91%E4%BB%AC%E8%8D%A1%E8%B5%B7%E9%A3%9E%E6%A1%A8/%E9%A3%9E%E6%A1%A8_%E8%8B%B1%E9%9B%84%E8%81%94%E7%9B%9F/main.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m model\u001b[39m.\u001b[39mprepare(optimizer\u001b[39m=\u001b[39mpaddle\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m, parameters\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mparameters()), \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E9%A1%B9%E7%9B%AE/%E8%AE%A9%E6%88%91%E4%BB%AC%E8%8D%A1%E8%B5%B7%E9%A3%9E%E6%A1%A8/%E9%A3%9E%E6%A1%A8_%E8%8B%B1%E9%9B%84%E8%81%94%E7%9B%9F/main.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m               loss\u001b[39m=\u001b[39mpaddle\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mMSELoss(), \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E9%A1%B9%E7%9B%AE/%E8%AE%A9%E6%88%91%E4%BB%AC%E8%8D%A1%E8%B5%B7%E9%A3%9E%E6%A1%A8/%E9%A3%9E%E6%A1%A8_%E8%8B%B1%E9%9B%84%E8%81%94%E7%9B%9F/main.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m               metrics\u001b[39m=\u001b[39mpaddle\u001b[39m.\u001b[39mmetric\u001b[39m.\u001b[39mAccuracy())\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E9%A1%B9%E7%9B%AE/%E8%AE%A9%E6%88%91%E4%BB%AC%E8%8D%A1%E8%B5%B7%E9%A3%9E%E6%A1%A8/%E9%A3%9E%E6%A1%A8_%E8%8B%B1%E9%9B%84%E8%81%94%E7%9B%9F/main.ipynb#W5sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# 启动模型训练，指定训练数据集，设置训练轮次，设置每次数据集计算的批次大小，设置日志格式\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/%E9%A1%B9%E7%9B%AE/%E8%AE%A9%E6%88%91%E4%BB%AC%E8%8D%A1%E8%B5%B7%E9%A3%9E%E6%A1%A8/%E9%A3%9E%E6%A1%A8_%E8%8B%B1%E9%9B%84%E8%81%94%E7%9B%9F/main.ipynb#W5sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_dataset, \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E9%A1%B9%E7%9B%AE/%E8%AE%A9%E6%88%91%E4%BB%AC%E8%8D%A1%E8%B5%B7%E9%A3%9E%E6%A1%A8/%E9%A3%9E%E6%A1%A8_%E8%8B%B1%E9%9B%84%E8%81%94%E7%9B%9F/main.ipynb#W5sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m           test_dataset,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E9%A1%B9%E7%9B%AE/%E8%AE%A9%E6%88%91%E4%BB%AC%E8%8D%A1%E8%B5%B7%E9%A3%9E%E6%A1%A8/%E9%A3%9E%E6%A1%A8_%E8%8B%B1%E9%9B%84%E8%81%94%E7%9B%9F/main.ipynb#W5sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m           epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E9%A1%B9%E7%9B%AE/%E8%AE%A9%E6%88%91%E4%BB%AC%E8%8D%A1%E8%B5%B7%E9%A3%9E%E6%A1%A8/%E9%A3%9E%E6%A1%A8_%E8%8B%B1%E9%9B%84%E8%81%94%E7%9B%9F/main.ipynb#W5sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m           batch_size\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E9%A1%B9%E7%9B%AE/%E8%AE%A9%E6%88%91%E4%BB%AC%E8%8D%A1%E8%B5%B7%E9%A3%9E%E6%A1%A8/%E9%A3%9E%E6%A1%A8_%E8%8B%B1%E9%9B%84%E8%81%94%E7%9B%9F/main.ipynb#W5sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m           verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Administer\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\paddle\\hapi\\model.py:1767\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, train_data, eval_data, batch_size, epochs, eval_freq, log_freq, save_dir, save_freq, verbose, drop_last, shuffle, num_workers, callbacks, accumulate_grad_batches, num_iters)\u001b[0m\n\u001b[0;32m   1765\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m   1766\u001b[0m     cbks\u001b[39m.\u001b[39mon_epoch_begin(epoch)\n\u001b[1;32m-> 1767\u001b[0m     logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_one_epoch(train_loader, cbks, \u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m   1768\u001b[0m     cbks\u001b[39m.\u001b[39mon_epoch_end(epoch, logs)\n\u001b[0;32m   1770\u001b[0m     \u001b[39mif\u001b[39;00m do_eval \u001b[39mand\u001b[39;00m epoch \u001b[39m%\u001b[39m eval_freq \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Administer\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\paddle\\hapi\\model.py:2097\u001b[0m, in \u001b[0;36mModel._run_one_epoch\u001b[1;34m(self, data_loader, callbacks, mode, logs)\u001b[0m\n\u001b[0;32m   2093\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m   2094\u001b[0m     _inputs\u001b[39m.\u001b[39mappend((step \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accumulate \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m\n\u001b[0;32m   2095\u001b[0m                    step \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(data_loader))\n\u001b[1;32m-> 2097\u001b[0m outs \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, mode \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m_batch\u001b[39;49m\u001b[39m'\u001b[39;49m)(\u001b[39m*\u001b[39;49m_inputs)\n\u001b[0;32m   2099\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metrics \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_loss:\n\u001b[0;32m   2100\u001b[0m     metrics \u001b[39m=\u001b[39m [[l[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m outs[\u001b[39m0\u001b[39m]]]\n",
      "File \u001b[1;32mc:\\Users\\Administer\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\paddle\\hapi\\model.py:1093\u001b[0m, in \u001b[0;36mModel.train_batch\u001b[1;34m(self, inputs, labels, update)\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_batch\u001b[39m(\u001b[39mself\u001b[39m, inputs, labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, update\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m   1046\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1047\u001b[0m \u001b[39m    Run one training step on one batch of data. And using `update` indicates\u001b[39;00m\n\u001b[0;32m   1048\u001b[0m \u001b[39m    whether optimizer update gradients computing by this batch.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1091\u001b[0m \u001b[39m          print(loss)\u001b[39;00m\n\u001b[0;32m   1092\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1093\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_adapter\u001b[39m.\u001b[39;49mtrain_batch(inputs, labels, update)\n\u001b[0;32m   1094\u001b[0m     \u001b[39mif\u001b[39;00m fluid\u001b[39m.\u001b[39m_non_static_mode() \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_info \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1095\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inputs()\n",
      "File \u001b[1;32mc:\\Users\\Administer\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\paddle\\hapi\\model.py:730\u001b[0m, in \u001b[0;36mDynamicGraphAdapter.train_batch\u001b[1;34m(self, inputs, labels, update)\u001b[0m\n\u001b[0;32m    726\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    727\u001b[0m         outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mnetwork\u001b[39m.\u001b[39mforward(\n\u001b[0;32m    728\u001b[0m             \u001b[39m*\u001b[39m[to_variable(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m inputs])\n\u001b[1;32m--> 730\u001b[0m losses \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49m_loss(\u001b[39m*\u001b[39;49m(to_list(outputs) \u001b[39m+\u001b[39;49m labels))\n\u001b[0;32m    731\u001b[0m losses \u001b[39m=\u001b[39m to_list(losses)\n\u001b[0;32m    732\u001b[0m final_loss \u001b[39m=\u001b[39m fluid\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39msum(losses)\n",
      "File \u001b[1;32mc:\\Users\\Administer\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\paddle\\fluid\\dygraph\\layers.py:930\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    928\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(\u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    929\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 930\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dygraph_call_func(\u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Administer\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\paddle\\fluid\\dygraph\\layers.py:915\u001b[0m, in \u001b[0;36mLayer._dygraph_call_func\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    913\u001b[0m         outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(\u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    914\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 915\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(\u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    917\u001b[0m \u001b[39mfor\u001b[39;00m forward_post_hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_post_hooks\u001b[39m.\u001b[39mvalues():\n\u001b[0;32m    918\u001b[0m     hook_result \u001b[39m=\u001b[39m forward_post_hook(\u001b[39mself\u001b[39m, inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\Administer\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\paddle\\nn\\layer\\loss.py:604\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[1;34m(self, input, label)\u001b[0m\n\u001b[0;32m    599\u001b[0m     fluid\u001b[39m.\u001b[39mdata_feeder\u001b[39m.\u001b[39mcheck_variable_and_dtype(\n\u001b[0;32m    600\u001b[0m         \u001b[39minput\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minput\u001b[39m\u001b[39m'\u001b[39m, [\u001b[39m'\u001b[39m\u001b[39mfloat32\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfloat64\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mMSELoss\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    601\u001b[0m     fluid\u001b[39m.\u001b[39mdata_feeder\u001b[39m.\u001b[39mcheck_variable_and_dtype(\n\u001b[0;32m    602\u001b[0m         label, \u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m, [\u001b[39m'\u001b[39m\u001b[39mfloat32\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfloat64\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mMSELoss\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 604\u001b[0m square_out \u001b[39m=\u001b[39m paddle\u001b[39m.\u001b[39msquare(paddle\u001b[39m.\u001b[39;49msubtract(\u001b[39minput\u001b[39;49m, label))\n\u001b[0;32m    605\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreduction \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    606\u001b[0m     \u001b[39mreturn\u001b[39;00m square_out\n",
      "File \u001b[1;32mc:\\Users\\Administer\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\paddle\\tensor\\math.py:360\u001b[0m, in \u001b[0;36msubtract\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m     \u001b[39mif\u001b[39;00m _in_legacy_dygraph():\n\u001b[1;32m--> 360\u001b[0m         \u001b[39mreturn\u001b[39;00m _elementwise_op_in_dygraph(\n\u001b[0;32m    361\u001b[0m             x, y, axis\u001b[39m=\u001b[39;49maxis, act\u001b[39m=\u001b[39;49mact, op_name\u001b[39m=\u001b[39;49mop_type)\n\u001b[0;32m    362\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    363\u001b[0m         \u001b[39mreturn\u001b[39;00m _elementwise_op(LayerHelper(op_type, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mlocals\u001b[39m()))\n",
      "File \u001b[1;32mc:\\Users\\Administer\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[39m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[39mreturn\u001b[39;00m caller(func, \u001b[39m*\u001b[39m(extras \u001b[39m+\u001b[39m args), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\Administer\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\paddle\\fluid\\wrapped_decorator.py:25\u001b[0m, in \u001b[0;36mwrap_decorator.<locals>.__impl__\u001b[1;34m(func, *args, **kwargs)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39m@decorator\u001b[39m\u001b[39m.\u001b[39mdecorator\n\u001b[0;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__impl__\u001b[39m(func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     24\u001b[0m     wrapped_func \u001b[39m=\u001b[39m decorator_func(func)\n\u001b[1;32m---> 25\u001b[0m     \u001b[39mreturn\u001b[39;00m wrapped_func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Administer\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\paddle\\fluid\\framework.py:434\u001b[0m, in \u001b[0;36m_dygraph_only_.<locals>.__impl__\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__impl__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    432\u001b[0m     \u001b[39massert\u001b[39;00m _non_static_mode(\n\u001b[0;32m    433\u001b[0m     ), \u001b[39m\"\u001b[39m\u001b[39mWe only support \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m()\u001b[39m\u001b[39m'\u001b[39m\u001b[39m in dynamic graph mode, please call \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpaddle.disable_static()\u001b[39m\u001b[39m'\u001b[39m\u001b[39m to enter dynamic graph mode.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m--> 434\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Administer\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\paddle\\tensor\\math.py:210\u001b[0m, in \u001b[0;36m_elementwise_op_in_dygraph\u001b[1;34m(x, y, axis, act, use_mkldnn, op_name)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[39mif\u001b[39;00m op_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m OP_NAMEMAPPING\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m    209\u001b[0m     op \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(_C_ops, op_name)\n\u001b[1;32m--> 210\u001b[0m     out \u001b[39m=\u001b[39m op(x, y, \u001b[39m'\u001b[39;49m\u001b[39maxis\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, \u001b[39m'\u001b[39;49m\u001b[39muse_mkldnn\u001b[39;49m\u001b[39m'\u001b[39;49m, use_mkldnn)\n\u001b[0;32m    211\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    212\u001b[0m     \u001b[39mif\u001b[39;00m in_dygraph_mode():\n",
      "\u001b[1;31mValueError\u001b[0m: (InvalidArgument) The type of data we are trying to retrieve does not match the type of data currently contained in the container.\n  [Hint: Expected dtype() == paddle::experimental::CppTypeToDataType<T>::Type(), but received dtype():7 != paddle::experimental::CppTypeToDataType<T>::Type():12.] (at C:\\home\\workspace\\Paddle_release\\paddle\\phi\\core\\dense_tensor.cc:137)\n  [operator < elementwise_sub > error]"
     ]
    }
   ],
   "source": [
    "\n",
    "# paddle.device.set_device('gpu:0')  # 本地显卡MX150没装CUDA\n",
    "# 封装模型为一个 model 实例，便于进行后续的训练、评估和推理\n",
    "model = paddle.Model(lenet_Sequential)\n",
    "# 为模型训练做准备，设置优化器及其学习率，并将网络的参数传入优化器，设置损失函数和精度计算方式\n",
    "model.prepare(optimizer=paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters()), \n",
    "              loss=paddle.nn.MSELoss(), \n",
    "              metrics=paddle.metric.Accuracy())\n",
    "# 启动模型训练，指定训练数据集，设置训练轮次，设置每次数据集计算的批次大小，设置日志格式\n",
    "model.fit(train_dataset, \n",
    "          test_dataset,\n",
    "          epochs=1, \n",
    "          batch_size=1,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T06:13:58.661994Z",
     "iopub.status.busy": "2022-08-11T06:13:58.661280Z",
     "iopub.status.idle": "2022-08-11T06:13:58.667996Z",
     "shell.execute_reply": "2022-08-11T06:13:58.667375Z",
     "shell.execute_reply.started": "2022-08-11T06:13:58.661965Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T09:14:27.803135Z",
     "iopub.status.busy": "2022-08-01T09:14:27.801768Z",
     "iopub.status.idle": "2022-08-01T09:15:31.589010Z",
     "shell.execute_reply": "2022-08-01T09:15:31.587871Z",
     "shell.execute_reply.started": "2022-08-01T09:14:27.803093Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8472\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "538aa17ce8a0584118ce85ff12bec826ccfc3555eae6360211bc5883b796f561"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
